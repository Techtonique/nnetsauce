install.packages("randtoolbox")
randtoolbox::sobol(5, 3)
?randtoolbox::sobol(5, 3)
?randtoolbox::sobol(10, 5)
randtoolbox::sobol(10, 5)
randtoolbox::sobol(7, 4)
0.0014672279357910156/0.0026183128356933594
0.0016782283782958984/ 0.004824161529541016
0.001*1000
0.11119198799133301/0.35703396797180176
0.10985136032104492/0.3593292236328125
0.00044417381286621094/0.0018596649169921875
1/0.14285714
library(nnetsauce)
library(nnetsauce)
?nnetsauce::BaseRegressor
set.seed(123)
n <- 50 ; p <- 3
X <- matrix(rnorm(n * p), n, p) # no intercept!
y <- rnorm(n)
obj <- nnetsauce::BaseRegressor(n_hidden_features=10L, dropout=0.9)
print(obj$fit(X, y))
print(obj$score(X, y))
?nnetsauce::CustomClassifier
library(datasets)
X <- as.matrix(iris[, 1:4])
y <- as.integer(iris[, 5]) - 1L
obj <- sklearn$tree$DecisionTreeClassifier()
obj2 <- CustomClassifier(obj)
obj2$fit(X, y)
print(obj2$score(X, y))
?nnetsauce::MTS
set.seed(123)
X <- matrix(rnorm(300), 100, 3)
obj <- sklearn$linear_model$ElasticNet()
obj2 <- MTS(obj)
obj2$fit(X)
obj2$predict()
install.packages("microbenchmark")
library(microbenchmark)
microbenchmark::microbenchmark(obj2$fit(X))
microbenchmark::microbenchmark(obj2$predict())
