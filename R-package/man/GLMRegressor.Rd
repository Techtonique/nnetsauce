% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/glm.R
\name{GLMRegressor}
\alias{GLMRegressor}
\title{Generalized nonlinear models for continuous output (regression)}
\usage{
GLMRegressor(
  n_hidden_features = 5L,
  lambda1 = 0.01,
  alpha1 = 0.5,
  lambda2 = 0.01,
  alpha2 = 0.5,
  family = "gaussian",
  activation_name = "relu",
  a = 0.01,
  nodes_sim = "sobol",
  bias = TRUE,
  dropout = 0,
  direct_link = TRUE,
  n_clusters = 2L,
  cluster_encode = TRUE,
  type_clust = "kmeans",
  type_scaling = c("std", "std", "std"),
  optimizer = ns$Optimizer(),
  seed = 123L
)
}
\description{
Parameters' description can be found at \url{https://techtonique.github.io/nnetsauce/}
}
\examples{

set.seed(123)
n <- 50 ; p <- 3
X <- matrix(rnorm(n * p), n, p) # no intercept!
y <- rnorm(n)

(index_train <- base::sample.int(n = nrow(X),
                                 size = floor(0.8*nrow(X)),
                                 replace = FALSE))
X_train <- X[index_train, ]
y_train <- y[index_train]
X_test <- X[-index_train, ]
y_test <- y[-index_train]

obj <- GLMRegressor()
obj$fit(X_train, y_train)
print(obj$score(X_test, y_test))

}
