{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<a target=\"_blank\" href=\"https://colab.research.google.com/github/Techtonique/nnetsauce/blob/master/nnetsauce/demo/thierrymoudiki_20240519_deep_qrns.ipynb\">\n",
        "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
        "</a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D-XLr3X7KTtb"
      },
      "source": [
        "# 1 - utils"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "LnH3e7MdMd4H"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: nnetsauce in ./venv/lib/python3.11/site-packages (0.20.1)\n",
            "Requirement already satisfied: numpy in ./venv/lib/python3.11/site-packages (1.26.4)\n",
            "Requirement already satisfied: scipy in ./venv/lib/python3.11/site-packages (1.13.0)\n",
            "Requirement already satisfied: scikit-learn in ./venv/lib/python3.11/site-packages (1.4.2)\n",
            "Requirement already satisfied: pandas in ./venv/lib/python3.11/site-packages (2.2.2)\n",
            "Requirement already satisfied: tqdm in ./venv/lib/python3.11/site-packages (4.66.4)\n",
            "Requirement already satisfied: joblib in ./venv/lib/python3.11/site-packages (1.4.2)\n",
            "Requirement already satisfied: category_encoders in ./venv/lib/python3.11/site-packages (2.6.3)\n",
            "Requirement already satisfied: ucimlrepo in ./venv/lib/python3.11/site-packages (0.0.6)\n",
            "Requirement already satisfied: matplotlib in ./venv/lib/python3.11/site-packages (from nnetsauce) (3.9.0)\n",
            "Requirement already satisfied: requests in ./venv/lib/python3.11/site-packages (from nnetsauce) (2.31.0)\n",
            "Requirement already satisfied: threadpoolctl in ./venv/lib/python3.11/site-packages (from nnetsauce) (3.5.0)\n",
            "Requirement already satisfied: jax in ./venv/lib/python3.11/site-packages (from nnetsauce) (0.4.28)\n",
            "Requirement already satisfied: jaxlib in ./venv/lib/python3.11/site-packages (from nnetsauce) (0.4.28)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in ./venv/lib/python3.11/site-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in ./venv/lib/python3.11/site-packages (from pandas) (2024.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in ./venv/lib/python3.11/site-packages (from pandas) (2024.1)\n",
            "Requirement already satisfied: statsmodels>=0.9.0 in ./venv/lib/python3.11/site-packages (from category_encoders) (0.14.2)\n",
            "Requirement already satisfied: patsy>=0.5.1 in ./venv/lib/python3.11/site-packages (from category_encoders) (0.5.6)\n",
            "Requirement already satisfied: six in ./venv/lib/python3.11/site-packages (from patsy>=0.5.1->category_encoders) (1.16.0)\n",
            "Requirement already satisfied: packaging>=21.3 in ./venv/lib/python3.11/site-packages (from statsmodels>=0.9.0->category_encoders) (24.0)\n",
            "Requirement already satisfied: ml-dtypes>=0.2.0 in ./venv/lib/python3.11/site-packages (from jax->nnetsauce) (0.4.0)\n",
            "Requirement already satisfied: opt-einsum in ./venv/lib/python3.11/site-packages (from jax->nnetsauce) (3.3.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in ./venv/lib/python3.11/site-packages (from matplotlib->nnetsauce) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in ./venv/lib/python3.11/site-packages (from matplotlib->nnetsauce) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in ./venv/lib/python3.11/site-packages (from matplotlib->nnetsauce) (4.51.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in ./venv/lib/python3.11/site-packages (from matplotlib->nnetsauce) (1.4.5)\n",
            "Requirement already satisfied: pillow>=8 in ./venv/lib/python3.11/site-packages (from matplotlib->nnetsauce) (10.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in ./venv/lib/python3.11/site-packages (from matplotlib->nnetsauce) (3.1.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in ./venv/lib/python3.11/site-packages (from requests->nnetsauce) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in ./venv/lib/python3.11/site-packages (from requests->nnetsauce) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in ./venv/lib/python3.11/site-packages (from requests->nnetsauce) (2.2.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in ./venv/lib/python3.11/site-packages (from requests->nnetsauce) (2024.2.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install nnetsauce numpy scipy scikit-learn pandas tqdm joblib category_encoders ucimlrepo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "ASS50zkWXhug"
      },
      "outputs": [],
      "source": [
        "import pandas\n",
        "pandas.options.display.float_format = '{:,.4f}'.format"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DvQ2qspfKY3L"
      },
      "source": [
        "## 1 - 1 Replace nan with median"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "1bVtfJEtKGpn"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "def replace_nan_with_median(arr):\n",
        "    # Calculate the median of each column ignoring NaN values\n",
        "    median_vals = np.nanmedian(arr, axis=0)\n",
        "\n",
        "    # Iterate over each column index and replace NaN with the corresponding median value\n",
        "    for col_idx in range(arr.shape[1]):\n",
        "        col_values = arr[:, col_idx]\n",
        "        nan_indices = np.isnan(col_values)\n",
        "        if np.any(nan_indices):\n",
        "            col_values[nan_indices] = median_vals[col_idx]\n",
        "\n",
        "    return arr"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jm-Q3iMQLOxp"
      },
      "source": [
        "## 1 - 2 Ids for UCIML repo data sets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "ZwwSjSfNLAwo"
      },
      "outputs": [],
      "source": [
        "# Data Type: Tabular; Task: Classification;\n",
        "# Features 10 to 100; #Instances 100 to 1000\n",
        "DATASETS_IDS_UCIML = [109, 759, 936,\n",
        "                      915, 942, 890, 848,\n",
        "                      967]\n",
        "\n",
        "DATASETS_SKLEARN = [\"iris\", \"wine\", \"breast_cancer\",\n",
        "                    \"covertype\", \"kddcup99\", \"adult\"]\n",
        "\n",
        "NROWS = 1000                    "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "61TTG_UeZqAo"
      },
      "source": [
        "## 1 - 3 Obtain data sets of size (1000, 10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "lo6c2s85ZoHG"
      },
      "outputs": [],
      "source": [
        "def select_NROWS_ten(X, y):\n",
        "    print(f\"X.shape (initial): {X.shape}\")\n",
        "    print(f\"y.shape (initial): {y.shape}\")\n",
        "    print(\"Encoding features and response...\")\n",
        "    le = LabelEncoder()\n",
        "    encoder = ce.HashingEncoder(return_df=False)\n",
        "    X = np.asarray(encoder.fit_transform(X, y)).astype(np.float32)\n",
        "    y = np.asarray(le.fit_transform(y)).astype(np.uint8)\n",
        "    print(\"Done.\")\n",
        "    print(\"Finding top 10 features if necessary...\")\n",
        "    if X.shape[1] > 10:\n",
        "        rf = RandomForestClassifier(n_estimators=50, random_state=42)\n",
        "        rf.fit(X, y)\n",
        "        indices = np.argsort(rf.feature_importances_)[::-1]\n",
        "        top_ten_indices = indices[:10]\n",
        "        print(f\"Top 10 indices: {top_ten_indices}\")\n",
        "        X = X[:,top_ten_indices]\n",
        "        print(f\"X reduced shape: {X.shape}\")\n",
        "    print(\"Done.\")\n",
        "    if X.shape[0] > NROWS:\n",
        "      print(f\"Subsampling to {NROWS} if necessary...\")\n",
        "      start = time()\n",
        "      sub = ns.SubSampler(y=y.ravel().astype(np.uint8),\n",
        "                          n_samples=NROWS, seed=123, n_jobs=-1)\n",
        "      idx_rows  = sub.subsample().ravel()\n",
        "      print(f\"... Elapsed time for subsampling: {time() - start}\")\n",
        "      print(\"Number of rows in the subsample: \", len(idx_rows))\n",
        "      print(\"Rows in the subsample: \", idx_rows)\n",
        "      return_X = replace_nan_with_median(X[idx_rows,:])\n",
        "      return_y = y[idx_rows].ravel().astype(np.uint8)\n",
        "      print(\"Done.\")\n",
        "      return return_X, return_y\n",
        "    else:\n",
        "      return X, y\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zj2LyNT1KucO"
      },
      "source": [
        "# 2 - Download data sets from UCI ML repo and sklearn"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Roz3kA6LX0J"
      },
      "source": [
        "## 2 - 1 UCI ML data sets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "JgTDVIdPKzpU"
      },
      "outputs": [],
      "source": [
        "import joblib\n",
        "import nnetsauce as ns\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from time import time\n",
        "from ucimlrepo import fetch_ucirepo\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import category_encoders as ce\n",
        "\n",
        "def load_uciml_data(dataset_id):\n",
        "  # fetch dataset\n",
        "  dataset = fetch_ucirepo(id=int(dataset_id))\n",
        "  le = LabelEncoder()\n",
        "  encoder = ce.HashingEncoder(return_df=True)\n",
        "  # data (as pandas dataframes)\n",
        "  y = le.fit_transform(dataset.data.targets.values)\n",
        "  X = encoder.fit_transform(dataset.data.features, y)\n",
        "  if len(y) > NROWS:\n",
        "      print(\"Subsampling...\")\n",
        "      start = time()\n",
        "      sub = ns.SubSampler(y=y.ravel().astype(np.uint8),\n",
        "                          n_samples=NROWS,\n",
        "                          seed=123,\n",
        "                          n_jobs=-1)\n",
        "      idx_rows  = sub.subsample()\n",
        "      X, y = X.copy().iloc[idx_rows,:], y.copy()[idx_rows] # X is a data frame\n",
        "      print(f\"Elapsed time for subsampling: {time() - start}\")\n",
        "  X.fillna(X.median(), inplace=True)\n",
        "  print(f\"dataset_id: {dataset_id} --------------------\")\n",
        "  print(f\"# of classes: {len(np.unique(y))}\")\n",
        "  return select_NROWS_ten(X.values.astype(np.float32), y.ravel().astype(np.uint8))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7MIXpdpSMMnt"
      },
      "source": [
        "## 2 - 2 `sklearn`'s/TabSurvey real-world data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "WJz3OLFVL7JX"
      },
      "outputs": [],
      "source": [
        "import category_encoders as ce\n",
        "import sklearn.datasets\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "import nnetsauce as ns\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.datasets import load_wine, load_iris, load_breast_cancer\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder, OneHotEncoder\n",
        "from time import time\n",
        "from functools import lru_cache\n",
        "\n",
        "\n",
        "def discretize_colum(data_clm, num_values=10):\n",
        "    \"\"\" Discretize a column by quantiles \"\"\"\n",
        "    r = np.argsort(data_clm)\n",
        "    bin_sz = (len(r) / num_values) + 1  # make sure all quantiles are in range 0-(num_quarts-1)\n",
        "    q = r // bin_sz\n",
        "    return q\n",
        "\n",
        "\n",
        "def load_data_sklearn(dataset=\"covertype\"):\n",
        "\n",
        "    print(\"Loading dataset \" + dataset + \"...\")\n",
        "\n",
        "    if dataset == \"breast_cancer\":\n",
        "      loaded_dataset = load_breast_cancer()\n",
        "      X, y = select_NROWS_ten(loaded_dataset.data, loaded_dataset.target)\n",
        "\n",
        "    elif dataset == \"iris\":\n",
        "      loaded_dataset = load_iris()\n",
        "      X, y = loaded_dataset.data, loaded_dataset.target\n",
        "\n",
        "    elif dataset == \"wine\":\n",
        "      loaded_dataset = load_wine()\n",
        "      X, y = loaded_dataset.data, loaded_dataset.target\n",
        "\n",
        "    elif dataset == \"covertype\":  # Multi-class classification dataset\n",
        "        X_temp, y_temp = sklearn.datasets.fetch_covtype(return_X_y=True)\n",
        "        print(\"Is data frame: \", isinstance(X_temp, pd.DataFrame))\n",
        "        X, y = select_NROWS_ten(X_temp, y_temp)\n",
        "\n",
        "    elif dataset == \"kddcup99\":  # Multi-class classification dataset with categorical data\n",
        "        X_temp, y_temp = sklearn.datasets.fetch_kddcup99(return_X_y=True)\n",
        "        print(\"Is data frame: \", isinstance(X_temp, pd.DataFrame))\n",
        "        X, y = select_NROWS_ten(X_temp, y_temp)\n",
        "\n",
        "    elif dataset == \"adult\" or dataset == \"adultcat\":  # Binary classification dataset with categorical data, if you pass AdultCat, the numerical columns will be discretized.\n",
        "        url_data = \"https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.data\"\n",
        "\n",
        "        features = ['age', 'workclass', 'fnlwgt', 'education', 'education_num', 'marital-status', 'occupation',\n",
        "                    'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'hours-per-week', 'native-country']\n",
        "        label = \"income\"\n",
        "        columns = features + [label]\n",
        "        df = pd.read_csv(url_data, names=columns)\n",
        "\n",
        "        # Fill NaN with something better?\n",
        "        df.fillna(0, inplace=True)\n",
        "        if dataset == \"adultcat\":\n",
        "            columns_to_discr = [('age', 10), ('fnlwgt', 25), ('capital-gain', 10), ('capital-loss', 10),\n",
        "                                ('hours-per-week', 10)]\n",
        "            for clm, nvals in columns_to_discr:\n",
        "                df[clm] = discretize_colum(df[clm], num_values=nvals)\n",
        "                df[clm] = df[clm].astype(int).astype(str)\n",
        "            df['education_num'] = df['education_num'].astype(int).astype(str)\n",
        "        X_temp = df[features].to_numpy()\n",
        "        y_temp = df[label].to_numpy()\n",
        "        return select_NROWS_ten(X_temp, y_temp)\n",
        "    else:\n",
        "        raise AttributeError(\"Dataset \\\"\" + dataset + \"\\\" not available\")\n",
        "\n",
        "    print(\"Dataset loaded!\")\n",
        "    print(X.shape)\n",
        "\n",
        "    return X, y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T2liO12zcaAc"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G-lYjJu-W-0s"
      },
      "source": [
        "# 3 - Create data sets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "_9sVGAV7XBXw"
      },
      "outputs": [],
      "source": [
        "## check #1\n",
        "#idx_dataset = 8 # 0 to 8\n",
        "#load_uciml_data(DATASETS_IDS_UCIML[idx_dataset])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "tfMMgytkXvGJ"
      },
      "outputs": [],
      "source": [
        "## check #2\n",
        "#idx_dataset2 = 5 # 0 to 5\n",
        "#load_data_sklearn(DATASETS_SKLEARN[idx_dataset2])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "uWTmTgPYhvxi"
      },
      "outputs": [],
      "source": [
        "#Xys = []\n",
        "\n",
        "#for idx_dataset in range(len(DATASETS_IDS_UCIML)):\n",
        "#  Xys.append(load_uciml_data(DATASETS_IDS_UCIML[idx_dataset]))\n",
        "\n",
        "#for idx_dataset2 in range(len(DATASETS_SKLEARN)):\n",
        "#  Xys.append(load_data_sklearn(DATASETS_SKLEARN[idx_dataset2]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "bt1uFKUEhh1n"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "import joblib\n",
        "#from google.colab import files\n",
        "\n",
        "#warnings.filterwarnings('ignore')\n",
        "\n",
        "#joblib.dump(Xys, \"Xys.pkl\")\n",
        "#files.download(\"Xys.pkl\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Jz3QBUinxuP"
      },
      "source": [
        "# 4 - Try import + fit baselines"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nYyp6jaLW70_"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Mf3DcWpHOGIB"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: joblib in ./venv/lib/python3.11/site-packages (1.4.2)\n",
            "Requirement already satisfied: tabpfn in ./venv/lib/python3.11/site-packages (0.1.10)\n",
            "Requirement already satisfied: nnetsauce in ./venv/lib/python3.11/site-packages (0.20.1)\n",
            "Requirement already satisfied: xgboost in ./venv/lib/python3.11/site-packages (2.0.3)\n",
            "Requirement already satisfied: scikit-optimize in ./venv/lib/python3.11/site-packages (0.10.1)\n",
            "Requirement already satisfied: numpy>=1.21.2 in ./venv/lib/python3.11/site-packages (from tabpfn) (1.26.4)\n",
            "Requirement already satisfied: pyyaml>=5.4.1 in ./venv/lib/python3.11/site-packages (from tabpfn) (6.0.1)\n",
            "Requirement already satisfied: requests>=2.23.0 in ./venv/lib/python3.11/site-packages (from tabpfn) (2.31.0)\n",
            "Requirement already satisfied: scikit-learn>=0.24.2 in ./venv/lib/python3.11/site-packages (from tabpfn) (1.4.2)\n",
            "Requirement already satisfied: torch>=1.9.0 in ./venv/lib/python3.11/site-packages (from tabpfn) (2.2.2)\n",
            "Requirement already satisfied: matplotlib in ./venv/lib/python3.11/site-packages (from nnetsauce) (3.9.0)\n",
            "Requirement already satisfied: pandas in ./venv/lib/python3.11/site-packages (from nnetsauce) (2.2.2)\n",
            "Requirement already satisfied: scipy in ./venv/lib/python3.11/site-packages (from nnetsauce) (1.13.0)\n",
            "Requirement already satisfied: threadpoolctl in ./venv/lib/python3.11/site-packages (from nnetsauce) (3.5.0)\n",
            "Requirement already satisfied: tqdm in ./venv/lib/python3.11/site-packages (from nnetsauce) (4.66.4)\n",
            "Requirement already satisfied: jax in ./venv/lib/python3.11/site-packages (from nnetsauce) (0.4.28)\n",
            "Requirement already satisfied: jaxlib in ./venv/lib/python3.11/site-packages (from nnetsauce) (0.4.28)\n",
            "Requirement already satisfied: pyaml>=16.9 in ./venv/lib/python3.11/site-packages (from scikit-optimize) (24.4.0)\n",
            "Requirement already satisfied: packaging>=21.3 in ./venv/lib/python3.11/site-packages (from scikit-optimize) (24.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in ./venv/lib/python3.11/site-packages (from requests>=2.23.0->tabpfn) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in ./venv/lib/python3.11/site-packages (from requests>=2.23.0->tabpfn) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in ./venv/lib/python3.11/site-packages (from requests>=2.23.0->tabpfn) (2.2.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in ./venv/lib/python3.11/site-packages (from requests>=2.23.0->tabpfn) (2024.2.2)\n",
            "Requirement already satisfied: filelock in ./venv/lib/python3.11/site-packages (from torch>=1.9.0->tabpfn) (3.14.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in ./venv/lib/python3.11/site-packages (from torch>=1.9.0->tabpfn) (4.11.0)\n",
            "Requirement already satisfied: sympy in ./venv/lib/python3.11/site-packages (from torch>=1.9.0->tabpfn) (1.12)\n",
            "Requirement already satisfied: networkx in ./venv/lib/python3.11/site-packages (from torch>=1.9.0->tabpfn) (3.3)\n",
            "Requirement already satisfied: jinja2 in ./venv/lib/python3.11/site-packages (from torch>=1.9.0->tabpfn) (3.1.4)\n",
            "Requirement already satisfied: fsspec in ./venv/lib/python3.11/site-packages (from torch>=1.9.0->tabpfn) (2024.5.0)\n",
            "Requirement already satisfied: ml-dtypes>=0.2.0 in ./venv/lib/python3.11/site-packages (from jax->nnetsauce) (0.4.0)\n",
            "Requirement already satisfied: opt-einsum in ./venv/lib/python3.11/site-packages (from jax->nnetsauce) (3.3.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in ./venv/lib/python3.11/site-packages (from matplotlib->nnetsauce) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in ./venv/lib/python3.11/site-packages (from matplotlib->nnetsauce) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in ./venv/lib/python3.11/site-packages (from matplotlib->nnetsauce) (4.51.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in ./venv/lib/python3.11/site-packages (from matplotlib->nnetsauce) (1.4.5)\n",
            "Requirement already satisfied: pillow>=8 in ./venv/lib/python3.11/site-packages (from matplotlib->nnetsauce) (10.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in ./venv/lib/python3.11/site-packages (from matplotlib->nnetsauce) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in ./venv/lib/python3.11/site-packages (from matplotlib->nnetsauce) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in ./venv/lib/python3.11/site-packages (from pandas->nnetsauce) (2024.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in ./venv/lib/python3.11/site-packages (from pandas->nnetsauce) (2024.1)\n",
            "Requirement already satisfied: six>=1.5 in ./venv/lib/python3.11/site-packages (from python-dateutil>=2.7->matplotlib->nnetsauce) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in ./venv/lib/python3.11/site-packages (from jinja2->torch>=1.9.0->tabpfn) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in ./venv/lib/python3.11/site-packages (from sympy->torch>=1.9.0->tabpfn) (1.3.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install joblib tabpfn nnetsauce xgboost scikit-optimize"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "WfY60iR4n7yK"
      },
      "outputs": [],
      "source": [
        "import joblib\n",
        "import nnetsauce as ns\n",
        "from sklearn.model_selection import cross_val_score, train_test_split\n",
        "from sklearn.metrics import balanced_accuracy_score\n",
        "from sklearn.ensemble import ExtraTreesClassifier, RandomForestClassifier\n",
        "from tabpfn import TabPFNClassifier\n",
        "from time import time\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import warnings\n",
        "import xgboost as xgb\n",
        "from sklearn.exceptions import ConvergenceWarning, UndefinedMetricWarning\n",
        "from skopt import BayesSearchCV\n",
        "from skopt.space import Real, Categorical, Integer\n",
        "from sklearn.metrics import make_scorer, balanced_accuracy_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "pmeJ4qtsn1Zw"
      },
      "outputs": [],
      "source": [
        "Xys = joblib.load(\"../datasets/Xys.pkl\")\n",
        "\n",
        "scores_array = np.empty((14, 5))\n",
        "\n",
        "scores_array[:,:] = np.nan\n",
        "\n",
        "scores_df = pd.DataFrame(scores_array, columns=[\"lazy_deep\", \"rf\",\n",
        "                                                \"et\", \"tabpfn\",\n",
        "                                                \"xgboost\"])\n",
        "timings_df = pd.DataFrame(scores_array, columns=[\"lazy_deep\", \"rf\",\n",
        "                                                      \"et\", \"tabpfn\",\n",
        "                                                      \"xgboost\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(178, 10)\n",
            "(178,)\n",
            "(839, 10)\n",
            "(839,)\n",
            "(714, 10)\n",
            "(714,)\n",
            "(383, 9)\n",
            "(383,)\n",
            "(995, 10)\n",
            "(995,)\n",
            "(999, 10)\n",
            "(999,)\n",
            "(999, 10)\n",
            "(999,)\n",
            "(999, 10)\n",
            "(999,)\n",
            "(150, 4)\n",
            "(150,)\n",
            "(178, 13)\n",
            "(178,)\n",
            "(569, 10)\n",
            "(569,)\n",
            "(996, 10)\n",
            "(996,)\n",
            "(994, 8)\n",
            "(994,)\n",
            "(999, 8)\n",
            "(999,)\n"
          ]
        }
      ],
      "source": [
        "for elt in Xys:\n",
        "    print(elt[0].shape)\n",
        "    print(elt[1].shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "5LI_3JD_oA6w"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "data set #:1 --------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 12/12 [00:15<00:00,  1.29s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Elapsed: 15.918371200561523\n",
            "  balanced accuracy lazydeep (DeepSimpleMultitaskClassifier(AdaBoostRegressor)): 1.0\n",
            "Elapsed: 0.5418291091918945\n",
            "  balanced accuracy rf: 1.0\n",
            "Elapsed: 0.3734550476074219\n",
            "  balanced accuracy et: 1.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/t/Documents/Papers/to_submit/2024-05-04-neurips/lazyclassifier/notebook/venv/lib/python3.11/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Elapsed: 10.8556649684906\n",
            "  balanced accuracy tabpfn: 1.0\n",
            "Elapsed: 33.509448289871216\n",
            "  balanced accuracy xgboost: 1.0\n",
            "data set #:2 --------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/12 [00:00<?, ?it/s]/Users/t/Documents/Papers/to_submit/2024-05-04-neurips/lazyclassifier/notebook/venv/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
            "  warnings.warn(\n",
            "/Users/t/Documents/Papers/to_submit/2024-05-04-neurips/lazyclassifier/notebook/venv/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
            "  warnings.warn(\n",
            "100%|██████████| 12/12 [00:24<00:00,  2.02s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Elapsed: 24.821156978607178\n",
            "  balanced accuracy lazydeep (DeepMultitaskClassifier(AdaBoostRegressor)): 0.9240598228546537\n",
            "Elapsed: 0.6184830665588379\n",
            "  balanced accuracy rf: 0.8658341803397706\n",
            "Elapsed: 0.6047379970550537\n",
            "  balanced accuracy et: 0.8376651662552634\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/t/Documents/Papers/to_submit/2024-05-04-neurips/lazyclassifier/notebook/venv/lib/python3.11/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Elapsed: 57.47028183937073\n",
            "  balanced accuracy tabpfn: 0.917017569333527\n",
            "Elapsed: 70.97452807426453\n",
            "  balanced accuracy xgboost: 0.9010454479454044\n",
            "data set #:3 --------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/12 [00:00<?, ?it/s]/Users/t/Documents/Papers/to_submit/2024-05-04-neurips/lazyclassifier/notebook/venv/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
            "  warnings.warn(\n",
            "/Users/t/Documents/Papers/to_submit/2024-05-04-neurips/lazyclassifier/notebook/venv/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
            "  warnings.warn(\n",
            "100%|██████████| 12/12 [00:49<00:00,  4.09s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Elapsed: 50.47680902481079\n",
            "  balanced accuracy lazydeep (DeepCustomClassifier(AdaBoostClassifier)): 0.40251989389920423\n",
            "Elapsed: 0.7725811004638672\n",
            "  balanced accuracy rf: 0.3476765890558993\n",
            "Elapsed: 0.6546797752380371\n",
            "  balanced accuracy et: 0.3950781019746537\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/t/Documents/Papers/to_submit/2024-05-04-neurips/lazyclassifier/notebook/venv/lib/python3.11/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Elapsed: 52.246299743652344\n",
            "  balanced accuracy tabpfn: 0.3333333333333333\n",
            "Elapsed: 102.50091290473938\n",
            "  balanced accuracy xgboost: 0.34981334119265156\n",
            "data set #:4 --------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/12 [00:00<?, ?it/s]/Users/t/Documents/Papers/to_submit/2024-05-04-neurips/lazyclassifier/notebook/venv/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
            "  warnings.warn(\n",
            "/Users/t/Documents/Papers/to_submit/2024-05-04-neurips/lazyclassifier/notebook/venv/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
            "  warnings.warn(\n",
            "100%|██████████| 12/12 [00:25<00:00,  2.12s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Elapsed: 26.25139617919922\n",
            "  balanced accuracy lazydeep (DeepCustomClassifier(ExtraTreesClassifier)): 0.9245098039215687\n",
            "Elapsed: 0.6670870780944824\n",
            "  balanced accuracy rf: 0.8573529411764705\n",
            "Elapsed: 0.5556387901306152\n",
            "  balanced accuracy et: 0.8867647058823529\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/t/Documents/Papers/to_submit/2024-05-04-neurips/lazyclassifier/notebook/venv/lib/python3.11/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Elapsed: 24.03065299987793\n",
            "  balanced accuracy tabpfn: 0.9245098039215687\n",
            "Elapsed: 73.7140793800354\n",
            "  balanced accuracy xgboost: 0.8450980392156863\n",
            "data set #:5 --------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/12 [00:00<?, ?it/s]/Users/t/Documents/Papers/to_submit/2024-05-04-neurips/lazyclassifier/notebook/venv/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
            "  warnings.warn(\n",
            "/Users/t/Documents/Papers/to_submit/2024-05-04-neurips/lazyclassifier/notebook/venv/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
            "  warnings.warn(\n",
            "  8%|▊         | 1/12 [00:01<00:20,  1.85s/it]/Users/t/Documents/Papers/to_submit/2024-05-04-neurips/lazyclassifier/notebook/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:2458: UserWarning: y_pred contains classes not in y_true\n",
            "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
            " 17%|█▋        | 2/12 [00:02<00:13,  1.35s/it]/Users/t/Documents/Papers/to_submit/2024-05-04-neurips/lazyclassifier/notebook/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:2458: UserWarning: y_pred contains classes not in y_true\n",
            "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
            " 33%|███▎      | 4/12 [00:06<00:13,  1.70s/it]/Users/t/Documents/Papers/to_submit/2024-05-04-neurips/lazyclassifier/notebook/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:2458: UserWarning: y_pred contains classes not in y_true\n",
            "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
            " 42%|████▏     | 5/12 [00:13<00:25,  3.62s/it]/Users/t/Documents/Papers/to_submit/2024-05-04-neurips/lazyclassifier/notebook/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:2458: UserWarning: y_pred contains classes not in y_true\n",
            "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
            " 50%|█████     | 6/12 [00:20<00:27,  4.60s/it]/Users/t/Documents/Papers/to_submit/2024-05-04-neurips/lazyclassifier/notebook/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:2458: UserWarning: y_pred contains classes not in y_true\n",
            "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
            " 67%|██████▋   | 8/12 [00:41<00:27,  6.96s/it]/Users/t/Documents/Papers/to_submit/2024-05-04-neurips/lazyclassifier/notebook/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:2458: UserWarning: y_pred contains classes not in y_true\n",
            "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
            " 75%|███████▌  | 9/12 [00:46<00:18,  6.28s/it]/Users/t/Documents/Papers/to_submit/2024-05-04-neurips/lazyclassifier/notebook/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:2458: UserWarning: y_pred contains classes not in y_true\n",
            "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
            " 83%|████████▎ | 10/12 [00:48<00:10,  5.15s/it]/Users/t/Documents/Papers/to_submit/2024-05-04-neurips/lazyclassifier/notebook/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:2458: UserWarning: y_pred contains classes not in y_true\n",
            "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
            "100%|██████████| 12/12 [01:00<00:00,  5.00s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Elapsed: 60.720869064331055\n",
            "  balanced accuracy lazydeep (DeepSimpleMultitaskClassifier(SVR)): 0.7982993197278913\n",
            "Elapsed: 1.0290651321411133\n",
            "  balanced accuracy rf: 0.7440476190476192\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/t/Documents/Papers/to_submit/2024-05-04-neurips/lazyclassifier/notebook/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:2458: UserWarning: y_pred contains classes not in y_true\n",
            "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
            "/Users/t/Documents/Papers/to_submit/2024-05-04-neurips/lazyclassifier/notebook/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:2458: UserWarning: y_pred contains classes not in y_true\n",
            "  warnings.warn(\"y_pred contains classes not in y_true\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Elapsed: 0.6665999889373779\n",
            "  balanced accuracy et: 0.7535714285714287\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/t/Documents/Papers/to_submit/2024-05-04-neurips/lazyclassifier/notebook/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:2458: UserWarning: y_pred contains classes not in y_true\n",
            "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
            "/Users/t/Documents/Papers/to_submit/2024-05-04-neurips/lazyclassifier/notebook/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:2458: UserWarning: y_pred contains classes not in y_true\n",
            "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
            "/Users/t/Documents/Papers/to_submit/2024-05-04-neurips/lazyclassifier/notebook/venv/lib/python3.11/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Elapsed: 70.9992790222168\n",
            "  balanced accuracy tabpfn: 0.85\n",
            "Elapsed: 113.80038595199585\n",
            "  balanced accuracy xgboost: 0.6862244897959184\n",
            "data set #:6 --------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/t/Documents/Papers/to_submit/2024-05-04-neurips/lazyclassifier/notebook/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:2458: UserWarning: y_pred contains classes not in y_true\n",
            "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
            "/Users/t/Documents/Papers/to_submit/2024-05-04-neurips/lazyclassifier/notebook/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:2458: UserWarning: y_pred contains classes not in y_true\n",
            "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
            "  0%|          | 0/12 [00:00<?, ?it/s]/Users/t/Documents/Papers/to_submit/2024-05-04-neurips/lazyclassifier/notebook/venv/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
            "  warnings.warn(\n",
            "/Users/t/Documents/Papers/to_submit/2024-05-04-neurips/lazyclassifier/notebook/venv/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
            "  warnings.warn(\n",
            "100%|██████████| 12/12 [00:22<00:00,  1.88s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Elapsed: 23.202695846557617\n",
            "  balanced accuracy lazydeep (DeepSimpleMultitaskClassifier(ExtraTreesRegressor)): 0.868382710053424\n",
            "Elapsed: 0.8924689292907715\n",
            "  balanced accuracy rf: 0.8374210781932977\n",
            "Elapsed: 0.584679365158081\n",
            "  balanced accuracy et: 0.8460417678484702\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/t/Documents/Papers/to_submit/2024-05-04-neurips/lazyclassifier/notebook/venv/lib/python3.11/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Elapsed: 107.22565197944641\n",
            "  balanced accuracy tabpfn: 0.868382710053424\n",
            "Elapsed: 76.66879796981812\n",
            "  balanced accuracy xgboost: 0.8805245264691597\n",
            "data set #:7 --------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/12 [00:00<?, ?it/s]/Users/t/Documents/Papers/to_submit/2024-05-04-neurips/lazyclassifier/notebook/venv/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
            "  warnings.warn(\n",
            "/Users/t/Documents/Papers/to_submit/2024-05-04-neurips/lazyclassifier/notebook/venv/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
            "  warnings.warn(\n",
            "100%|██████████| 12/12 [01:08<00:00,  5.68s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Elapsed: 69.21928882598877\n",
            "  balanced accuracy lazydeep (DeepSimpleMultitaskClassifier(ExtraTreesRegressor)): 0.9340155257586451\n",
            "Elapsed: 1.8620860576629639\n",
            "  balanced accuracy rf: 0.9349228752898477\n",
            "Elapsed: 1.4548838138580322\n",
            "  balanced accuracy et: 0.9322008266962396\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/t/Documents/Papers/to_submit/2024-05-04-neurips/lazyclassifier/notebook/venv/lib/python3.11/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Elapsed: 87.02385401725769\n",
            "  balanced accuracy tabpfn: 0.9175320092751285\n",
            "Elapsed: 16.957337856292725\n",
            "  balanced accuracy xgboost: 0.901048492791612\n",
            "data set #:8 --------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/12 [00:00<?, ?it/s]/Users/t/Documents/Papers/to_submit/2024-05-04-neurips/lazyclassifier/notebook/venv/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
            "  warnings.warn(\n",
            "/Users/t/Documents/Papers/to_submit/2024-05-04-neurips/lazyclassifier/notebook/venv/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
            "  warnings.warn(\n",
            "100%|██████████| 12/12 [00:24<00:00,  2.04s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Elapsed: 25.20522427558899\n",
            "  balanced accuracy lazydeep (DeepCustomClassifier(AdaBoostClassifier)): 1.0\n",
            "Elapsed: 1.4238839149475098\n",
            "  balanced accuracy rf: 1.0\n",
            "Elapsed: 0.5890712738037109\n",
            "  balanced accuracy et: 1.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/t/Documents/Papers/to_submit/2024-05-04-neurips/lazyclassifier/notebook/venv/lib/python3.11/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Elapsed: 67.35388588905334\n",
            "  balanced accuracy tabpfn: 1.0\n",
            "Elapsed: 12.342914819717407\n",
            "  balanced accuracy xgboost: 1.0\n",
            "data set #:9 --------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/12 [00:00<?, ?it/s]/Users/t/Documents/Papers/to_submit/2024-05-04-neurips/lazyclassifier/notebook/venv/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
            "  warnings.warn(\n",
            "/Users/t/Documents/Papers/to_submit/2024-05-04-neurips/lazyclassifier/notebook/venv/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
            "  warnings.warn(\n",
            "100%|██████████| 12/12 [00:15<00:00,  1.26s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Elapsed: 15.84173583984375\n",
            "  balanced accuracy lazydeep (DeepCustomClassifier(BaggingClassifier)): 1.0\n",
            "Elapsed: 0.6872539520263672\n",
            "  balanced accuracy rf: 0.9393939393939394\n",
            "Elapsed: 0.40033984184265137\n",
            "  balanced accuracy et: 0.9696969696969697\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/t/Documents/Papers/to_submit/2024-05-04-neurips/lazyclassifier/notebook/venv/lib/python3.11/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Elapsed: 6.466933965682983\n",
            "  balanced accuracy tabpfn: 0.9090909090909092\n",
            "Elapsed: 29.612331867218018\n",
            "  balanced accuracy xgboost: 0.9393939393939394\n",
            "data set #:10 --------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/12 [00:00<?, ?it/s]/Users/t/Documents/Papers/to_submit/2024-05-04-neurips/lazyclassifier/notebook/venv/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
            "  warnings.warn(\n",
            "/Users/t/Documents/Papers/to_submit/2024-05-04-neurips/lazyclassifier/notebook/venv/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
            "  warnings.warn(\n",
            "100%|██████████| 12/12 [00:13<00:00,  1.16s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Elapsed: 14.316891193389893\n",
            "  balanced accuracy lazydeep (DeepSimpleMultitaskClassifier(AdaBoostRegressor)): 1.0\n",
            "Elapsed: 0.5630757808685303\n",
            "  balanced accuracy rf: 1.0\n",
            "Elapsed: 0.4758110046386719\n",
            "  balanced accuracy et: 1.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/t/Documents/Papers/to_submit/2024-05-04-neurips/lazyclassifier/notebook/venv/lib/python3.11/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Elapsed: 6.820991039276123\n",
            "  balanced accuracy tabpfn: 0.9803921568627452\n",
            "Elapsed: 22.6512131690979\n",
            "  balanced accuracy xgboost: 1.0\n",
            "data set #:11 --------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/12 [00:00<?, ?it/s]/Users/t/Documents/Papers/to_submit/2024-05-04-neurips/lazyclassifier/notebook/venv/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
            "  warnings.warn(\n",
            "/Users/t/Documents/Papers/to_submit/2024-05-04-neurips/lazyclassifier/notebook/venv/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
            "  warnings.warn(\n",
            "100%|██████████| 12/12 [00:18<00:00,  1.53s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Elapsed: 18.744131088256836\n",
            "  balanced accuracy lazydeep (DeepMultitaskClassifier(ExtraTreesRegressor)): 0.975609756097561\n",
            "Elapsed: 0.7693641185760498\n",
            "  balanced accuracy rf: 0.9687604410290678\n",
            "Elapsed: 0.4544851779937744\n",
            "  balanced accuracy et: 0.9687604410290678\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/t/Documents/Papers/to_submit/2024-05-04-neurips/lazyclassifier/notebook/venv/lib/python3.11/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Elapsed: 28.19751501083374\n",
            "  balanced accuracy tabpfn: 0.975609756097561\n",
            "Elapsed: 14.778143882751465\n",
            "  balanced accuracy xgboost: 0.9687604410290678\n",
            "data set #:12 --------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/12 [00:00<?, ?it/s]/Users/t/Documents/Papers/to_submit/2024-05-04-neurips/lazyclassifier/notebook/venv/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
            "  warnings.warn(\n",
            "/Users/t/Documents/Papers/to_submit/2024-05-04-neurips/lazyclassifier/notebook/venv/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
            "  warnings.warn(\n",
            "100%|██████████| 12/12 [00:39<00:00,  3.30s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Elapsed: 39.87502908706665\n",
            "  balanced accuracy lazydeep (DeepMultitaskClassifier(AdaBoostRegressor)): 0.5517618040873855\n",
            "Elapsed: 1.0847280025482178\n",
            "  balanced accuracy rf: 0.35260117789187556\n",
            "Elapsed: 1.1039371490478516\n",
            "  balanced accuracy et: 0.33899124131682273\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/t/Documents/Papers/to_submit/2024-05-04-neurips/lazyclassifier/notebook/venv/lib/python3.11/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Elapsed: 61.29803681373596\n",
            "  balanced accuracy tabpfn: 0.33724327997583814\n",
            "Elapsed: 102.93468689918518\n",
            "  balanced accuracy xgboost: 0.4312216852914527\n",
            "data set #:13 --------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/12 [00:00<?, ?it/s]/Users/t/Documents/Papers/to_submit/2024-05-04-neurips/lazyclassifier/notebook/venv/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
            "  warnings.warn(\n",
            "/Users/t/Documents/Papers/to_submit/2024-05-04-neurips/lazyclassifier/notebook/venv/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
            "  warnings.warn(\n",
            "  8%|▊         | 1/12 [00:01<00:13,  1.22s/it]/Users/t/Documents/Papers/to_submit/2024-05-04-neurips/lazyclassifier/notebook/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:2458: UserWarning: y_pred contains classes not in y_true\n",
            "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
            " 17%|█▋        | 2/12 [00:02<00:09,  1.03it/s]/Users/t/Documents/Papers/to_submit/2024-05-04-neurips/lazyclassifier/notebook/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:2458: UserWarning: y_pred contains classes not in y_true\n",
            "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
            "100%|██████████| 12/12 [00:05<00:00,  2.27it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Elapsed: 5.642559051513672\n",
            "  balanced accuracy lazydeep (DeepCustomClassifier(ExtraTreesClassifier)): 0.5877551020408164\n",
            "Elapsed: 0.5576310157775879\n",
            "  balanced accuracy rf: 0.5795918367346939\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/t/Documents/Papers/to_submit/2024-05-04-neurips/lazyclassifier/notebook/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:2458: UserWarning: y_pred contains classes not in y_true\n",
            "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
            "/Users/t/Documents/Papers/to_submit/2024-05-04-neurips/lazyclassifier/notebook/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:2458: UserWarning: y_pred contains classes not in y_true\n",
            "  warnings.warn(\"y_pred contains classes not in y_true\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Elapsed: 0.4942011833190918\n",
            "  balanced accuracy et: 0.5877551020408164\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/t/Documents/Papers/to_submit/2024-05-04-neurips/lazyclassifier/notebook/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:2458: UserWarning: y_pred contains classes not in y_true\n",
            "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
            "/Users/t/Documents/Papers/to_submit/2024-05-04-neurips/lazyclassifier/notebook/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:2458: UserWarning: y_pred contains classes not in y_true\n",
            "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
            "/Users/t/Documents/Papers/to_submit/2024-05-04-neurips/lazyclassifier/notebook/venv/lib/python3.11/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Elapsed: 73.90874004364014\n",
            "  balanced accuracy tabpfn: 0.5836734693877551\n",
            "data set #:14 --------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/t/Documents/Papers/to_submit/2024-05-04-neurips/lazyclassifier/notebook/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:2458: UserWarning: y_pred contains classes not in y_true\n",
            "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
            "/Users/t/Documents/Papers/to_submit/2024-05-04-neurips/lazyclassifier/notebook/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:2458: UserWarning: y_pred contains classes not in y_true\n",
            "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
            "  0%|          | 0/12 [00:00<?, ?it/s]/Users/t/Documents/Papers/to_submit/2024-05-04-neurips/lazyclassifier/notebook/venv/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
            "  warnings.warn(\n",
            "/Users/t/Documents/Papers/to_submit/2024-05-04-neurips/lazyclassifier/notebook/venv/lib/python3.11/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
            "  warnings.warn(\n",
            "100%|██████████| 12/12 [00:26<00:00,  2.21s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Elapsed: 27.08159112930298\n",
            "  balanced accuracy lazydeep (DeepMultitaskClassifier(ExtraTreesRegressor)): 0.5620039682539683\n",
            "Elapsed: 0.8359658718109131\n",
            "  balanced accuracy rf: 0.5238095238095238\n",
            "Elapsed: 0.6228969097137451\n",
            "  balanced accuracy et: 0.5223214285714286\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/t/Documents/Papers/to_submit/2024-05-04-neurips/lazyclassifier/notebook/venv/lib/python3.11/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Elapsed: 56.68902921676636\n",
            "  balanced accuracy tabpfn: 0.5054563492063492\n",
            "Elapsed: 9.532980918884277\n",
            "  balanced accuracy xgboost: 0.5545634920634921\n"
          ]
        }
      ],
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
        "from scipy.stats import uniform, randint\n",
        "\n",
        "# Define a custom scoring function using accuracy_score with normalize=True\n",
        "def balanced_accuracy(y_true, y_pred):\n",
        "    return balanced_accuracy_score(y_true, y_pred)\n",
        "\n",
        "balanced_accuracy_scorer = make_scorer(balanced_accuracy)\n",
        "\n",
        "# Define the warning types to ignore\n",
        "sklearn_warnings = (ConvergenceWarning, UndefinedMetricWarning, FutureWarning, UserWarning)\n",
        "\n",
        "with warnings.catch_warnings():\n",
        "\n",
        "  # Filter out specified warnings\n",
        "  warnings.filterwarnings('ignore')\n",
        "  warnings.simplefilter(\"ignore\")\n",
        "  for warning_type in sklearn_warnings:\n",
        "    warnings.filterwarnings(\"ignore\", category=warning_type)\n",
        "\n",
        "  for dataset_idx, (X, y) in enumerate(Xys):\n",
        "\n",
        "    print(f\"data set #:{dataset_idx + 1} --------------------\")\n",
        "    clf_lazydeep = ns.LazyDeepClassifier(verbose=0, ignore_warnings=True,\n",
        "                                #estimators=\"all\",\n",
        "                                estimators=[\"AdaBoostRegressor\",\n",
        "                                            \"BaggingRegressor\",\n",
        "                                            \"ExtraTreesRegressor\",\n",
        "                                            \"AdaBoostClassifier\",\n",
        "                                            \"BaggingClassifier\",\n",
        "                                            \"ExtraTreesClassifier\",\n",
        "                                            \"SVC\",\n",
        "                                            \"SVR\"],\n",
        "                                sort_by=\"Balanced Accuracy\")\n",
        "    clf_rf = RandomForestClassifier()\n",
        "    clf_et = ExtraTreesClassifier()\n",
        "    clf_tabpfn = TabPFNClassifier(device='cpu',\n",
        "                                  N_ensemble_configurations=32)\n",
        "    # clf_xgboost = BayesSearchCV(xgb.XGBClassifier(n_estimators=1000,\n",
        "    #                                       random_state=13),\n",
        "    #     {\n",
        "    #     'eta': Real(1e-4, 1e-1),\n",
        "    #     'max_depth': Integer( 1, 10),\n",
        "    #     'subsample': Real(0.5, 1.0),\n",
        "    #     'colsample_bytree': Real(0.5, 1.0),\n",
        "    #     #'min_child_weight': Integer(1, 20)\n",
        "    #     }, random_state=13,\n",
        "    #     n_iter=50,\n",
        "    #    cv=3,\n",
        "    #     scoring=balanced_accuracy_scorer,\n",
        "    #     #n_jobs = None,\n",
        "    #     verbose=0)\n",
        "    # clf_xgboost = xgb.XGBClassifier(random_state=13, \n",
        "    #                                 subsample=0.9, \n",
        "    #                                 colsample_bytree=0.9)\n",
        "    \n",
        "    # clf_xgboost = GridSearchCV(estimator=xgb.XGBClassifier(n_estimators=1000, \n",
        "    #                                                        random_state=13), \n",
        "    #                            param_grid={\n",
        "    #                             'eta': [0.001, 0.01, 0.1],  # example values, you can adjust based on your range\n",
        "    #                             'max_depth': [2, 5, 8],\n",
        "    #                             #'subsample': [0.5, 0.8, 1.0],\n",
        "    #                             #'colsample_bytree': [0.5, 0.8, 1.0]\n",
        "    #                               },\n",
        "    #                             scoring=balanced_accuracy_scorer,\n",
        "    #                             cv=3,\n",
        "    #                             verbose=2)\n",
        "\n",
        "    clf_xgboost = xgb.XGBClassifier(random_state=13,\n",
        "                                    n_estimators=1000,\n",
        "                                    eta=0.01,\n",
        "                                    max_depth=5,\n",
        "                                    subsample=0.8,\n",
        "                                    colsample_bytree=0.8)\n",
        "\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=123)\n",
        "\n",
        "    start = time()\n",
        "    models, _ = clf_lazydeep.fit(X_train, X_test, y_train, y_test)\n",
        "    timings_df.loc[dataset_idx, \"lazy_deep\"] = time()-start\n",
        "    print(f\"Elapsed: {timings_df.loc[dataset_idx, 'lazy_deep']}\")\n",
        "    print(f\"  balanced accuracy lazydeep ({models.index[0]}): {models.iloc[0, 1]}\")\n",
        "    scores_df.loc[dataset_idx, \"lazy_deep\"] = models.iloc[0, 1]\n",
        "\n",
        "    start = time()\n",
        "    preds_rf = clf_rf.fit(X_train, y_train).predict(X_test)\n",
        "    timings_df.loc[dataset_idx, \"rf\"] = time()-start\n",
        "    print(f\"Elapsed: {timings_df.loc[dataset_idx, 'rf']}\")\n",
        "    print(f\"  balanced accuracy rf: {balanced_accuracy_score(y_test, preds_rf)}\")\n",
        "    scores_df.loc[dataset_idx, \"rf\"] = balanced_accuracy_score(y_test, preds_rf)\n",
        "\n",
        "    start = time()\n",
        "    preds_et = clf_et.fit(X_train, y_train).predict(X_test)\n",
        "    timings_df.loc[dataset_idx, \"et\"] = time()-start\n",
        "    print(f\"Elapsed: {timings_df.loc[dataset_idx, 'et']}\")\n",
        "    print(f\"  balanced accuracy et: {balanced_accuracy_score(y_test, preds_et)}\")\n",
        "    scores_df.loc[dataset_idx, \"et\"] = balanced_accuracy_score(y_test, preds_et)\n",
        "\n",
        "    \n",
        "    start = time()\n",
        "    preds_tabpfn = clf_tabpfn.fit(X_train, y_train).predict(X_test)\n",
        "    timings_df.loc[dataset_idx, \"tabpfn\"] = time()-start\n",
        "    print(f\"Elapsed: {timings_df.loc[dataset_idx, 'tabpfn']}\")\n",
        "    print(f\"  balanced accuracy tabpfn: {balanced_accuracy_score(y_test, preds_tabpfn)}\")\n",
        "    scores_df.loc[dataset_idx, \"tabpfn\"] = balanced_accuracy_score(y_test, preds_tabpfn)\n",
        "  \n",
        "    try:\n",
        "      start = time()\n",
        "      preds_xgboost = clf_xgboost.fit(X_train, y_train).predict(X_test)\n",
        "      timings_df.loc[dataset_idx, \"xgboost\"] = time()-start\n",
        "      print(f\"Elapsed: {timings_df.loc[dataset_idx, 'xgboost']}\")\n",
        "      print(f\"  balanced accuracy xgboost: {balanced_accuracy_score(y_test, preds_xgboost)}\")\n",
        "      scores_df.loc[dataset_idx, \"xgboost\"] = balanced_accuracy_score(y_test, preds_xgboost)\n",
        "    except ValueError: \n",
        "      continue\n",
        "      \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "YUQHj18sPcb8"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>lazy_deep</th>\n",
              "      <th>rf</th>\n",
              "      <th>et</th>\n",
              "      <th>tabpfn</th>\n",
              "      <th>xgboost</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.92</td>\n",
              "      <td>0.87</td>\n",
              "      <td>0.84</td>\n",
              "      <td>0.92</td>\n",
              "      <td>0.83</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.40</td>\n",
              "      <td>0.35</td>\n",
              "      <td>0.40</td>\n",
              "      <td>0.33</td>\n",
              "      <td>0.33</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.92</td>\n",
              "      <td>0.86</td>\n",
              "      <td>0.89</td>\n",
              "      <td>0.92</td>\n",
              "      <td>0.85</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.80</td>\n",
              "      <td>0.74</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.85</td>\n",
              "      <td>0.69</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0.87</td>\n",
              "      <td>0.84</td>\n",
              "      <td>0.85</td>\n",
              "      <td>0.87</td>\n",
              "      <td>0.88</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0.93</td>\n",
              "      <td>0.93</td>\n",
              "      <td>0.93</td>\n",
              "      <td>0.92</td>\n",
              "      <td>0.93</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>1.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>1.00</td>\n",
              "      <td>0.94</td>\n",
              "      <td>0.97</td>\n",
              "      <td>0.91</td>\n",
              "      <td>0.97</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>1.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.98</td>\n",
              "      <td>1.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>0.98</td>\n",
              "      <td>0.97</td>\n",
              "      <td>0.97</td>\n",
              "      <td>0.98</td>\n",
              "      <td>0.97</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>0.55</td>\n",
              "      <td>0.35</td>\n",
              "      <td>0.34</td>\n",
              "      <td>0.34</td>\n",
              "      <td>0.44</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>0.59</td>\n",
              "      <td>0.58</td>\n",
              "      <td>0.59</td>\n",
              "      <td>0.58</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>0.56</td>\n",
              "      <td>0.52</td>\n",
              "      <td>0.52</td>\n",
              "      <td>0.51</td>\n",
              "      <td>0.56</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    lazy_deep   rf   et  tabpfn  xgboost\n",
              "0        1.00 1.00 1.00    1.00     1.00\n",
              "1        0.92 0.87 0.84    0.92     0.83\n",
              "2        0.40 0.35 0.40    0.33     0.33\n",
              "3        0.92 0.86 0.89    0.92     0.85\n",
              "4        0.80 0.74 0.75    0.85     0.69\n",
              "5        0.87 0.84 0.85    0.87     0.88\n",
              "6        0.93 0.93 0.93    0.92     0.93\n",
              "7        1.00 1.00 1.00    1.00     1.00\n",
              "8        1.00 0.94 0.97    0.91     0.97\n",
              "9        1.00 1.00 1.00    0.98     1.00\n",
              "10       0.98 0.97 0.97    0.98     0.97\n",
              "11       0.55 0.35 0.34    0.34     0.44\n",
              "12       0.59 0.58 0.59    0.58      NaN\n",
              "13       0.56 0.52 0.52    0.51     0.56"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "display(scores_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "seXCR2d9WAnw"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>lazy_deep</th>\n",
              "      <th>rf</th>\n",
              "      <th>et</th>\n",
              "      <th>tabpfn</th>\n",
              "      <th>xgboost</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5.00</td>\n",
              "      <td>5.00</td>\n",
              "      <td>5.00</td>\n",
              "      <td>5.00</td>\n",
              "      <td>5.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.00</td>\n",
              "      <td>3.00</td>\n",
              "      <td>4.00</td>\n",
              "      <td>2.00</td>\n",
              "      <td>5.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.00</td>\n",
              "      <td>3.00</td>\n",
              "      <td>2.00</td>\n",
              "      <td>4.00</td>\n",
              "      <td>5.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2.00</td>\n",
              "      <td>4.00</td>\n",
              "      <td>3.00</td>\n",
              "      <td>2.00</td>\n",
              "      <td>5.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2.00</td>\n",
              "      <td>4.00</td>\n",
              "      <td>3.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>5.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>3.00</td>\n",
              "      <td>5.00</td>\n",
              "      <td>4.00</td>\n",
              "      <td>3.00</td>\n",
              "      <td>1.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>2.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>3.00</td>\n",
              "      <td>5.00</td>\n",
              "      <td>4.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>5.00</td>\n",
              "      <td>5.00</td>\n",
              "      <td>5.00</td>\n",
              "      <td>5.00</td>\n",
              "      <td>5.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>1.00</td>\n",
              "      <td>4.00</td>\n",
              "      <td>3.00</td>\n",
              "      <td>5.00</td>\n",
              "      <td>3.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>4.00</td>\n",
              "      <td>4.00</td>\n",
              "      <td>4.00</td>\n",
              "      <td>5.00</td>\n",
              "      <td>4.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>2.00</td>\n",
              "      <td>5.00</td>\n",
              "      <td>5.00</td>\n",
              "      <td>2.00</td>\n",
              "      <td>5.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>1.00</td>\n",
              "      <td>3.00</td>\n",
              "      <td>4.00</td>\n",
              "      <td>5.00</td>\n",
              "      <td>2.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>2.00</td>\n",
              "      <td>4.00</td>\n",
              "      <td>2.00</td>\n",
              "      <td>3.00</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>1.00</td>\n",
              "      <td>3.00</td>\n",
              "      <td>4.00</td>\n",
              "      <td>5.00</td>\n",
              "      <td>2.00</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    lazy_deep   rf   et  tabpfn  xgboost\n",
              "0        5.00 5.00 5.00    5.00     5.00\n",
              "1        1.00 3.00 4.00    2.00     5.00\n",
              "2        1.00 3.00 2.00    4.00     5.00\n",
              "3        2.00 4.00 3.00    2.00     5.00\n",
              "4        2.00 4.00 3.00    1.00     5.00\n",
              "5        3.00 5.00 4.00    3.00     1.00\n",
              "6        2.00 1.00 3.00    5.00     4.00\n",
              "7        5.00 5.00 5.00    5.00     5.00\n",
              "8        1.00 4.00 3.00    5.00     3.00\n",
              "9        4.00 4.00 4.00    5.00     4.00\n",
              "10       2.00 5.00 5.00    2.00     5.00\n",
              "11       1.00 3.00 4.00    5.00     2.00\n",
              "12       2.00 4.00 2.00    3.00      NaN\n",
              "13       1.00 3.00 4.00    5.00     2.00"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "scores_ranks_df = scores_df.rank(axis=1, method='max', ascending=False)\n",
        "display(scores_ranks_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "_moW7HiiWQW5"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>lazy_deep</th>\n",
              "      <th>rf</th>\n",
              "      <th>et</th>\n",
              "      <th>tabpfn</th>\n",
              "      <th>xgboost</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>14.00</td>\n",
              "      <td>14.00</td>\n",
              "      <td>14.00</td>\n",
              "      <td>14.00</td>\n",
              "      <td>13.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>2.29</td>\n",
              "      <td>3.79</td>\n",
              "      <td>3.64</td>\n",
              "      <td>3.71</td>\n",
              "      <td>3.92</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>1.44</td>\n",
              "      <td>1.12</td>\n",
              "      <td>1.01</td>\n",
              "      <td>1.49</td>\n",
              "      <td>1.44</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>1.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>2.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>1.00</td>\n",
              "      <td>3.00</td>\n",
              "      <td>3.00</td>\n",
              "      <td>2.25</td>\n",
              "      <td>3.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>2.00</td>\n",
              "      <td>4.00</td>\n",
              "      <td>4.00</td>\n",
              "      <td>4.50</td>\n",
              "      <td>5.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>2.75</td>\n",
              "      <td>4.75</td>\n",
              "      <td>4.00</td>\n",
              "      <td>5.00</td>\n",
              "      <td>5.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>5.00</td>\n",
              "      <td>5.00</td>\n",
              "      <td>5.00</td>\n",
              "      <td>5.00</td>\n",
              "      <td>5.00</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       lazy_deep    rf    et  tabpfn  xgboost\n",
              "count      14.00 14.00 14.00   14.00    13.00\n",
              "mean        2.29  3.79  3.64    3.71     3.92\n",
              "std         1.44  1.12  1.01    1.49     1.44\n",
              "min         1.00  1.00  2.00    1.00     1.00\n",
              "25%         1.00  3.00  3.00    2.25     3.00\n",
              "50%         2.00  4.00  4.00    4.50     5.00\n",
              "75%         2.75  4.75  4.00    5.00     5.00\n",
              "max         5.00  5.00  5.00    5.00     5.00"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "scores_ranks_df.describe()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
