{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pUSgyoy5XVy_"
   },
   "source": [
    "This notebook __demonstrates the use of [`nnetsauce`](https://github.com/thierrymoudiki/nnetsauce)'s Adaboost classifier__ on two popular (and public) datasets. `nnetsauce`'s implementation of this algorithm has __some specificities__, as it will be shown in the sequel of this notebook. It is worth noting that the __current implementation is 100% in Python__. \n",
    "\n",
    "We start by installing the package's development version from Github (use the command line):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "lcVruPd3sZxm"
   },
   "outputs": [],
   "source": [
    "pip install git+https://github.com/thierrymoudiki/nnetsauce.git"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vAsrdnyDX1q1"
   },
   "source": [
    "Next, we __import the packages necessary for the job__, along with `nnetsauce` (namely `numpy` and `sklearn`, nothing weird!):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "H4lTsROEs2vn"
   },
   "outputs": [],
   "source": [
    "import nnetsauce as ns\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_breast_cancer, load_wine, load_iris\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oKgD8Da-YDIZ"
   },
   "source": [
    "Our __first example__ is based on `wisconsin breast cancer` dataset from [UCI (University of California at Irvine) repository](http://archive.ics.uci.edu/ml/index.php), and available in `sklearn`. More details about the content of these datasets can be found [here](http://archive.ics.uci.edu/ml/datasets/Breast+Cancer+Wisconsin+%28Diagnostic%29) and [here](http://archive.ics.uci.edu/ml/datasets/Wine).\n",
    "\n",
    "`wisconsin breast cancer` dataset is splitted into a __training set__ (for training the model to pattern recognition) and __test set__ (for model validation):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "SkRVrEKBaslV"
   },
   "outputs": [],
   "source": [
    "# Import dataset from sklearn\n",
    "breast_cancer = load_breast_cancer()\n",
    "X = breast_cancer.data\n",
    "y = breast_cancer.target\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, \n",
    "                                                    random_state=123)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lYBFb4F-at1M"
   },
   "source": [
    "The first version of Adaboost that we apply is __`SAMME.R`__, also known as Real Adaboost. `SAMME` stands for Stagewise Additive Modeling using a Multi-class Exponential loss function, and  [`nnetsauce`](https://github.com/thierrymoudiki/nnetsauce)'s implementation of this algorithm has some __specificities__:\n",
    "- The base learners are quasi-randomized (__deterministic__) networks\n",
    "- At each boosting iteration, a fraction of the datasets' rows or columns can be randomly chosen to increase diversity of the ensemble  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "nMBTcikts61e"
   },
   "outputs": [],
   "source": [
    "# SAMME.R\n",
    "\n",
    "# base learner\n",
    "clf = LogisticRegression(solver='liblinear', multi_class = 'ovr', \n",
    "                         random_state=123)\n",
    "\n",
    "# nnetsauce's Adaboost\n",
    "fit_obj = ns.AdaBoostClassifier(clf, \n",
    "                                n_hidden_features=11, \n",
    "                                direct_link=True,\n",
    "                                n_estimators=250, learning_rate=0.01126343,\n",
    "                                col_sample=0.72684326, row_sample=0.86429443,\n",
    "                                dropout=0.63078613, n_clusters=2,\n",
    "                                type_clust=\"gmm\",\n",
    "                                verbose=1, seed = 123, \n",
    "                                method=\"SAMME.R\")  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UN07dVFWdxGS"
   },
   "source": [
    "The base learner, `clf`, is a logistic regression model. __But it could be anything__, including decision trees. `fit_obj` is a `nnetsauce` object that augments `clf` with a hidden layer, and typically makes its predictions nonlinear. \n",
    "\n",
    "`n_hidden_features` is the number of nodes in the hidden layer, and `dropout` randomly drops some of these nodes at each boosting iteration. `col_sample` and `row_sample` specify the __fraction of columns and rows__ chosen for fitting the base learner at each  iteration. With `n_clusters`, the data can be clustered into homogeneous groups before model training.\n",
    "\n",
    "__`nnetsauce`'s Adaboost can now be fitted__; `250` iterations are used:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "uUOkbx8Ndcdp"
   },
   "outputs": [],
   "source": [
    "# Fitting the model to training set \n",
    "fit_obj.fit(X_train, y_train)  \n",
    "\n",
    "# Obtain model's accuracy on test set\n",
    "print(fit_obj.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eWAfkLL2hps9"
   },
   "source": [
    "With the following graph, we can __visualize how well our data have been classified__ by `nnetsauce`'s Adaboost."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 308
    },
    "colab_type": "code",
    "id": "P1-4JlqNhNd1",
    "outputId": "981a925c-3478-4d3d-9354-a49cd49e11c4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250/250 [██████████████████████████████] - 0s 906us/step\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAARIAAAESCAYAAAAxN1ojAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nMBYJEQljkRCRMBYJEQljkRCRsP8HBq/Pyz8l0P0AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns; sns.set()\n",
    "from sklearn.metrics import confusion_matrix\n",
    "preds = fit_obj.predict(X_test)\n",
    "mat = confusion_matrix(y_test, preds)\n",
    "sns.heatmap(mat.T, square=True, annot=True, fmt='d', cbar=False)\n",
    "plt.xlabel('true label')\n",
    "plt.ylabel('predicted label');\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "b6Ubm2pWr2zI"
   },
   "source": [
    "`1` denotes a malignant tumor, and `0`, its absence. For the 3 (out of 114) patients remaining missclassified, it could be interesting to change the model `sample_weight`s, in order to give them more weight in the learning procedure. Then, see how well the result evolves;  depending on which decision we consider being the worst (or best). But note that: \n",
    "- __The model will never be perfect__ (plus, the labels are based on human-eyed labelling ;) ). \n",
    "- Patients are not labelled. _Label_ is just a generic term in classification, for all types of classification models and data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "X58rk7YJZYMt"
   },
   "source": [
    "Our __second example__ is based on `wine` dataset from [UCI repository](http://archive.ics.uci.edu/ml/index.php). This dataset contains information about wines' quality, depending on their characteristics. `SAMME` is now used instead of `SAMME.R`. This second algorithm seems to require more iterations to converge than `SAMME.R` (but you, tell me from your experience!):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "4j0gnP_JuUcV"
   },
   "outputs": [],
   "source": [
    "# load dataset\n",
    "wine = load_wine()\n",
    "Z = wine.data\n",
    "t = wine.target\n",
    "np.random.seed(123)\n",
    "Z_train, Z_test, y_train, y_test = train_test_split(Z, t, test_size=0.2)\n",
    "\n",
    "\n",
    "# SAMME\n",
    "clf = LogisticRegression(solver='liblinear', multi_class = 'ovr', \n",
    "                         random_state=123)\n",
    "fit_obj = ns.AdaBoostClassifier(clf, \n",
    "                                n_hidden_features=np.int(8.21154785e+01), \n",
    "                                direct_link=True,\n",
    "                                n_estimators=1000, learning_rate=2.96252441e-02,\n",
    "                                col_sample=4.22766113e-01, row_sample=7.87268066e-01,\n",
    "                                dropout=1.56909180e-01, n_clusters=3,\n",
    "                                type_clust=\"gmm\",\n",
    "                                verbose=1, seed = 123, \n",
    "                                method=\"SAMME\") \n",
    " \n",
    " # Fitting the model to training set\n",
    "fit_obj.fit(Z_train, y_train)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kY9JYvuCkG9T"
   },
   "source": [
    "After fitting the model, we can obtain some statistics (`accuracy`, `precision`, `recall`, `f1-score`; every `nnetsauce` model is 100% `sklearn`-compatible) about it's quality:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "cNaCjOYIjzdJ"
   },
   "outputs": [],
   "source": [
    "preds = fit_obj.predict(Z_test)     \n",
    "print(metrics.classification_report(preds, y_test))    "
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "adaboost_classification.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
